{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5380edf-fadd-4e1c-8f68-8f4038760ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is the worst customer service</td>\n",
       "      <td>can you please send us a private message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i did</td>\n",
       "      <td>please send us a private message so that we ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>and how do you propose we do that i have sent ...</td>\n",
       "      <td>i understand i would like to assist you we wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>yall lie about your great connection 5 bars lt...</td>\n",
       "      <td>h there we would definitely like to work with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>since i signed up with yousince day 1</td>\n",
       "      <td>we understand your concerns and we would like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           question  \\\n",
       "0   0                      is the worst customer service   \n",
       "1   0                                              i did   \n",
       "2   0  and how do you propose we do that i have sent ...   \n",
       "3   1  yall lie about your great connection 5 bars lt...   \n",
       "4   1              since i signed up with yousince day 1   \n",
       "\n",
       "                                            response  \n",
       "0  can you please send us a private message so th...  \n",
       "1  please send us a private message so that we ca...  \n",
       "2  i understand i would like to assist you we wou...  \n",
       "3  h there we would definitely like to work with ...  \n",
       "4  we understand your concerns and we would like ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "file_path = 'cleaned_data.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72590c-31d3-4e2f-a76e-12cf86336864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13925/13925 [==============================] - 147550s 11s/step - loss: 0.2349 - accuracy: 0.9698 - val_loss: 0.0289 - val_accuracy: 0.9972\n",
      "Epoch 2/10\n",
      "13925/13925 [==============================] - 148279s 11s/step - loss: 0.0188 - accuracy: 0.9980 - val_loss: 0.0197 - val_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "13925/13925 [==============================] - 147521s 11s/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.0174 - val_accuracy: 0.9984\n",
      "Epoch 4/10\n",
      "13925/13925 [==============================] - 148762s 11s/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0166 - val_accuracy: 0.9985\n",
      "Epoch 5/10\n",
      "10763/13925 [======================>.......] - ETA: 8:22:01 - loss: 4.9173e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Converting the columns to strings\n",
    "df[\"question\"] = df[\"question\"].astype(str)\n",
    "df[\"response\"] = df[\"response\"].astype(str)\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining hyperparameters\n",
    "batch_size = 64  # Adjust as needed\n",
    "epochs = 10      # Number of training epochs\n",
    "\n",
    "# Initializing and fitting tokenizers for both questions and responses\n",
    "tokenizer_question = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer_response = Tokenizer(oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer_question.fit_on_texts(train_df[\"question\"])\n",
    "tokenizer_response.fit_on_texts(train_df[\"response\"])\n",
    "\n",
    "# Converting text data to sequences\n",
    "train_question_sequences = tokenizer_question.texts_to_sequences(train_df[\"question\"])\n",
    "train_response_sequences = tokenizer_response.texts_to_sequences(train_df[\"response\"])\n",
    "val_question_sequences = tokenizer_question.texts_to_sequences(val_df[\"question\"])\n",
    "val_response_sequences = tokenizer_response.texts_to_sequences(val_df[\"response\"])\n",
    "\n",
    "#Padding sequences to a fixed length\n",
    "max_sequence_length = 50 \n",
    "train_question_sequences = pad_sequences(train_question_sequences, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "train_response_sequences = pad_sequences(train_response_sequences, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "val_question_sequences = pad_sequences(val_question_sequences, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "val_response_sequences = pad_sequences(val_response_sequences, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "#reducing sample data size\n",
    "train_df_sample = train_df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "train_question_sequences = np.array(train_question_sequences)\n",
    "train_response_sequences = np.array(train_response_sequences)\n",
    "\n",
    "val_question_sequences = np.array(val_question_sequences)\n",
    "val_response_sequences = np.array(val_response_sequences)\n",
    "\n",
    "embedding_dim = 256  # Dimension of word embeddings\n",
    "hidden_units = 512   # Number of LSTM units\n",
    "input_vocab_size = len(tokenizer_question.word_index) + 1  \n",
    "target_vocab_size = len(tokenizer_response.word_index) + 1  # Vocabulary size for responses\n",
    "max_sequence_length = 50  # Maximum sequence length\n",
    "\n",
    "# Defining the encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
    "encoder_embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = tf.keras.layers.LSTM(hidden_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Defining the decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
    "decoder_embedding = tf.keras.layers.Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    [train_question_sequences, train_response_sequences],\n",
    "    train_response_sequences,\n",
    "    batch_size=batch_size,\n",
    "\n",
    "          \n",
    "    epochs=epochs,\n",
    "    validation_data=([val_question_sequences, val_response_sequences], val_response_sequences)\n",
    ")\n",
    "\n",
    "#saving model in h5 format. also save as a .keras extension \n",
    "model.save(\"seq2seq_lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a77216-9775-40fa-895b-1cedad0219c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class EarlyStoppingAtMinLoss(Callback):\n",
    "    def __init__(self, patience=2):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "        if current_val_loss is None:\n",
    "            return\n",
    "\n",
    "        if current_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"Epoch {epoch + 1}: Early stopping due to no improvement in validation loss.\")\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStoppingAtMinLoss(patience=2)  \n",
    "\n",
    "history = model.fit(\n",
    "    [train_question_sequences, train_response_sequences],\n",
    "    train_response_sequences,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([val_question_sequences, val_response_sequences], val_response_sequences),\n",
    "    callbacks=[early_stopping_callback]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff57be-bc02-4c4a-8e84-682b03b4b888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
