{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c70669-f67e-4d8e-907e-96dc9ca770e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 50, 256)              7155404   ['input_5[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 50, 256)              2338892   ['input_6[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, 512),                1574912   ['embedding_4[0][0]']         \n",
      "                              (None, 512),                                                        \n",
      "                              (None, 512)]                                                        \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               [(None, 50, 512),            1574912   ['embedding_5[0][0]',         \n",
      "                              (None, 512),                           'lstm_4[0][1]',              \n",
      "                              (None, 512)]                           'lstm_4[0][2]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 50, 91363)            4686921   ['lstm_5[0][0]']              \n",
      "                                                          9                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 144962019 (552.99 MB)\n",
      "Trainable params: 144962019 (552.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('weights_epoch_03_val_loss_0.0174.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d800e8-9197-4ee0-a773-3461db4d3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe6ee4d-30a5-4674-b196-6119163b6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\administrator\\venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\administrator\\venv\\lib\\site-packages (from pydot) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a53322-3bd0-4c7a-9172-a70052604740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9018c6d5-6190-49f7-9478-942ac7d6396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5 True\n",
      "input_6 True\n",
      "embedding_4 True\n",
      "embedding_5 True\n",
      "lstm_4 True\n",
      "lstm_5 True\n",
      "dense_2 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feccf03f-5f30-493c-957c-430546c68ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\administrator\\venv\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\administrator\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f8c286-e270-4130-9811-9f176f222d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Layer 1: input_5 - InputLayer\n",
      "  Input shape: [(None, 50)]\n",
      "  Output shape: [(None, 50)]\n",
      "\n",
      "Layer 2: input_6 - InputLayer\n",
      "  Input shape: [(None, 50)]\n",
      "  Output shape: [(None, 50)]\n",
      "\n",
      "Layer 3: embedding_4 - Embedding\n",
      "  Input shape: (None, 50)\n",
      "  Output shape: (None, 50, 256)\n",
      "\n",
      "Layer 4: embedding_5 - Embedding\n",
      "  Input shape: (None, 50)\n",
      "  Output shape: (None, 50, 256)\n",
      "\n",
      "Layer 5: lstm_4 - LSTM\n",
      "  Input shape: (None, 50, 256)\n",
      "  Output shape: [(None, 512), (None, 512), (None, 512)]\n",
      "\n",
      "Layer 6: lstm_5 - LSTM\n",
      "  Input shape: [(None, 50, 256), (None, 512), (None, 512)]\n",
      "  Output shape: [(None, 50, 512), (None, 512), (None, 512)]\n",
      "\n",
      "Layer 7: dense_2 - Dense\n",
      "  Input shape: (None, 50, 512)\n",
      "  Output shape: (None, 50, 91363)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def visualize_model(model):\n",
    "    print(\"Model Summary:\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        print(f\"Layer {i + 1}: {layer.name} - {layer.__class__.__name__}\")\n",
    "        print(f\"  Input shape: {layer.input_shape}\")\n",
    "        print(f\"  Output shape: {layer.output_shape}\\n\")\n",
    "\n",
    "visualize_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d98add4-d65e-494a-a8f9-7b92b7445f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\administrator\\venv\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fecaa7-780f-4ce3-b697-2c1bdbd45516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\administrator\\venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\administrator\\venv\\lib\\site-packages (from pydot) (3.1.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\administrator\\venv\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydot\n",
    "# !pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6eaee1-8b43-48f3-82ff-0079df40190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e078139c-1274-4ca1-953c-fa87ee1622f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Generated Response: you\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "Tokenized Input Sequence: [[ 93  20  80  60  11 144   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Generated Sequence: [[[2.7816264e-13 6.3966150e-13 2.8501461e-12 ... 7.5825034e-13\n",
      "   4.9068718e-12 6.3148820e-14]\n",
      "  [2.7239155e-17 3.5791847e-15 1.1291669e-13 ... 6.3926216e-15\n",
      "   1.7263965e-14 1.2136381e-15]\n",
      "  [6.9483291e-17 3.4916574e-15 5.1542864e-11 ... 1.4603557e-15\n",
      "   1.4194977e-14 1.8914338e-16]\n",
      "  ...\n",
      "  [1.0000000e+00 5.9444372e-14 5.3488043e-21 ... 1.9230209e-13\n",
      "   6.4003813e-15 7.7258722e-15]\n",
      "  [1.0000000e+00 5.9440747e-14 5.3486411e-21 ... 1.9229330e-13\n",
      "   6.4004787e-15 7.7252827e-15]\n",
      "  [1.0000000e+00 5.9440747e-14 5.3481512e-21 ... 1.9228743e-13\n",
      "   6.4004787e-15 7.7249295e-15]]]\n",
      "Generated Text: \n",
      "Generated Response: \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "questions = df['question'].astype(str).tolist()\n",
    "responses = df['response'].astype(str).tolist()\n",
    "\n",
    "# Create and fit the tokenizers for both questions and responses\n",
    "tokenizer_questions = Tokenizer()\n",
    "tokenizer_questions.fit_on_texts(questions)\n",
    "\n",
    "tokenizer_responses = Tokenizer()\n",
    "tokenizer_responses.fit_on_texts(responses)\n",
    "\n",
    "\n",
    "with open('tokenizer_questions.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_questions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('tokenizer_responses.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_responses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def generate_response(input_question):\n",
    "    if not isinstance(input_question, str):\n",
    "        input_question = str(input_question)\n",
    "\n",
    "    input_question_seq = tokenizer_questions.texts_to_sequences([input_question])\n",
    "\n",
    "    input_question_seq = pad_sequences(input_question_seq, maxlen=50, padding='post')\n",
    "\n",
    "    response_seq = model.predict([input_question_seq, input_question_seq])\n",
    "    generated_sequence = response_seq[0][-1]\n",
    "    generated_text = tokenizer_responses.sequences_to_texts([generated_sequence])[0]\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "\n",
    "input_inquiry = \"fix your app, its not working.\"\n",
    "generated_response = generate_response(input_inquiry)\n",
    "\n",
    "print(\"Generated Response:\", generated_response)\n",
    "\n",
    "\n",
    "def generate_response(input_question):\n",
    "    if not isinstance(input_question, str):\n",
    "        input_question = str(input_question)\n",
    "\n",
    "    input_question_seq = tokenizer_questions.texts_to_sequences([input_question])\n",
    "    \n",
    "    input_question_seq = pad_sequences(input_question_seq, maxlen=50, padding='post')\n",
    "    \n",
    "  \n",
    "    response_seq = model.predict([input_question_seq, input_question_seq])\n",
    "    \n",
    "    print(\"Tokenized Input Sequence:\", input_question_seq)\n",
    "    print(\"Generated Sequence:\", response_seq)\n",
    "    \n",
    "    generated_sequence = response_seq[0][-1]\n",
    "    generated_token_index = np.argmax(generated_sequence) \n",
    "    generated_text = tokenizer_responses.index_word.get(generated_token_index, '')\n",
    "    print(\"Generated Text:\", generated_text)\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "\n",
    "input_inquiry2 = \"fix your app, its not working.\"\n",
    "generated_response = generate_response(input_inquiry2)\n",
    "\n",
    "\n",
    "print(\"Generated Response:\", generated_response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bb2d0-e644-4b23-b227-dc3e7657710d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
